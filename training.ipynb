{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"training.ipynb","provenance":[],"collapsed_sections":["CjPVc6aB0KKH","WhclIyFQRdDT"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGtQZd9h_-uf","executionInfo":{"status":"ok","timestamp":1609514799706,"user_tz":-330,"elapsed":24483,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}},"outputId":"f9083966-880b-4cda-a6a8-69aa554fbd34"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CjPVc6aB0KKH"},"source":["# training and evaluation"]},{"cell_type":"code","metadata":{"id":"X1I62fBJ1S78"},"source":["! pip install Pillow-SIMD\n","! pip install facenet-pytorch\n","! pip install ffmpeg-python\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDfrb_lK0yjb","executionInfo":{"status":"ok","timestamp":1609516209738,"user_tz":-330,"elapsed":1010,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}}},"source":["import sys\n","sys.path.insert(0,'/content/drive/My Drive/my_projects/ISLR/Real-time-GesRec-master')\n","sys.path.insert(1,'/content/drive/My Drive/my_projects/ISLR')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDuJEVxPjltc","executionInfo":{"status":"ok","timestamp":1609516210212,"user_tz":-330,"elapsed":777,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}}},"source":["from pathlib import Path\n","\n","no_val=False#True\n","testset=False\n","\n","path_det=Path('/content/drive/My Drive/my_projects/ISLR/pretrained_models/egogesture_resnetl_10_RGB_8.pth')\n","path_clf=Path('/content/drive/My Drive/my_projects/ISLR/my_model/n/with_none/merged_testset/best_acc_model_state_dict.pth')\n","#pretrained_path_clf=Path('/content/drive/My Drive/my_projects/ISLR/model_checkpoint/checkpoint.pth')\n","pretrained_path_clf=Path('/content/drive/My Drive/my_projects/ISLR/pretrained_models/jester_resnext_101_RGB_16_best.pth')\n","#ann_path=Path('/content/drive/My Drive/my_projects/ISLR/annotation/annotation_0-9_w_nf_w_none.json')\n","ann_path=Path('/content/drive/My Drive/my_projects/ISLR/annotation/annotation_0-9_w_nf_w_none_mrg_testset.json')\n","\n","#vid_path='E:\\\\Faiz\\\\Projects\\\\My_Projects\\\\ISLR\\\\3DCNN\\\\my_video\\\\ego.mp4'\n","vid_path=''#'E:\\\\Faiz\\\\Projects\\\\My_Projects\\\\ISLR'\n","res_path=Path('/content/drive/My Drive/my_projects/ISLR/my_result')\n","root_path='/content/drive/My Drive/my_projects/ISLR'\n","classifier='resnext'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"yKFOHWzStHSG","executionInfo":{"status":"ok","timestamp":1609516212851,"user_tz":-330,"elapsed":1037,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}}},"source":["\n","class Opt():\n","    def __init__(self):\n","        self.root_path = root_path\n","        self.resume_path = ''  # path_jstr_clf\n","        self.sample_duration = 16\n","        self.pretrain_path = pretrained_path_clf\n","        self.is_pretrained_model_has_dropout=False           ##### only my models has dropout \n","        self.n_classes = 27\n","        self.n_finetune_classes = 11#10\n","\n","        self.model = classifier\n","        self.model_depth = 101\n","        self.width_mult = 1.0\n","        self.modality = 'RGB'\n","        self.resnet_shortcut = 'B'\n","        self.arch = ''\n","        self.scales = ''\n","        self.initial_scale = 1.0\n","        self.n_scales = 1\n","        self.scale_step = 0.84089641525\n","        self.ft_begin_index = 0\n","        self.ft_portion = 'last_layer'\n","        self.mean = [114.7748, 107.7354, 99.475]\n","        self.std = [38.7568578, 37.88248729, 40.02898126]\n","        self.resnext_cardinality = 32\n","        self.pretrain_modality = 'RGB'\n","        self.no_cuda = False\n","        self.norm_value = 1\n","        self.no_mean_norm = False\n","        self.std_norm = False\n","        self.sample_size = 112\n","        self.manual_seed = 1\n","        self.stride_len = 1\n","        self.video_path = vid_path\n","        self.annotation_path = ann_path\n","        self.result_path = res_path\n","        self.store_name = 'model'\n","        self.dataset = 'egogesture'\n","        self.no_train = False\n","        self.topk=1\n","        self.train_crop = 'center'\n","        self.downsample = 1               #### used in temporal transformation\n","        self.batch_size = 4\n","        self.n_threads = 0\n","        self.nesterov = True\n","        self.dampening = 0.9\n","        self.learning_rate = .01\n","        self.lr_steps = [150]#[8,16,20,23]#[10, 20, 30, 40, 100]\n","        self.momentum = 0.9\n","        self.weight_decay = 1e-3\n","        self.lr_patience = 10\n","        self.no_val = no_val\n","        self.n_val_samples=1\n","        self.val_batch_size=1#4\n","        self.begin_epoch = 1\n","        self.n_epochs = 1\n","        self.test=testset\n","        self.test_subset='test'\n","        self.test_batch_size=1#4\n","        #        self.scale_in_test=''\n","        #        self.crop_position_in_test=''\n","        \n","        self.mean_dataset = 'activitynet'\n","        self.with_egogesture = False\n","        self.train_validate = False\n","        self.feature_extracting=True\n","\n","        self.resnext_dropout=True\n","        self.resnext_dropout_prob=.5\n","\n","\n","        self.show_1_batch=False\n","        self.figsize=(6,6)\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"S7ogHsGy9fnq","executionInfo":{"status":"ok","timestamp":1609516213267,"user_tz":-330,"elapsed":659,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}}},"source":["resume=False\n","resume_path='/content/drive/My Drive/my_projects/ISLR/model_checkpoint/'+'with_none/wo_val_test/'+'checkpoint.pth'\n","\n","if resume:\n","  opening_mode='a'\n","else: opening_mode='w'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEAzxzpxm0eG","executionInfo":{"status":"ok","timestamp":1609516222767,"user_tz":-330,"elapsed":8954,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}},"outputId":"be96bc39-7410-432e-d9dc-d54ebe73f27f"},"source":["import os\n","import sys\n","import json\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.optim import lr_scheduler\n","\n","# from opts import parse_opts\n","from model import generate_model\n","from mean import get_mean, get_std\n","from spatial_transforms import *\n","from temporal_transforms import *\n","from target_transforms import ClassLabel, VideoID\n","from target_transforms import Compose as TargetCompose\n","from dataset import get_training_set, get_validation_set, get_test_set\n","from utils import *\n","from train import train_epoch\n","from validation import val_epoch\n","import test\n","\n","#from my_input import *\n","\n","best_prec1 = 0\n","\n","if __name__ == '__main__':\n","#    opt = parse_opts()\n","    opt = Opt()\n","    if opt.root_path != '':\n","        opt.video_path = os.path.join(opt.root_path, opt.video_path)\n","        opt.annotation_path = os.path.join(opt.root_path, opt.annotation_path)\n","        opt.result_path = os.path.join(opt.root_path, opt.result_path)\n","        if not os.path.exists(opt.result_path):\n","            os.makedirs(opt.result_path)\n","        if opt.resume_path:\n","            opt.resume_path = os.path.join(opt.root_path, opt.resume_path)\n","        if opt.pretrain_path:\n","            opt.pretrain_path = os.path.join(opt.root_path, opt.pretrain_path)\n","    opt.scales = [opt.initial_scale]\n","    for i in range(1, opt.n_scales):\n","        opt.scales.append(opt.scales[-1] * opt.scale_step)\n","    opt.arch = '{}'.format(opt.model)\n","    opt.mean = get_mean(opt.norm_value, dataset=opt.mean_dataset)\n","    opt.std = get_std(opt.norm_value)\n","    opt.store_name = '_'.join([opt.dataset, opt.model, str(opt.width_mult) + 'x',\n","                               opt.modality, str(opt.sample_duration)])\n","    \n","#    with open(os.path.join(opt.result_path, 'opts.json'), 'w') as opt_file:\n","#        json.dump(vars(opt), opt_file)\n","\n","    torch.manual_seed(opt.manual_seed)\n","    model=generate_model(opt)\n","    if isinstance(model,tuple):\n","       model, parameters = model\n","                        \n","#    for param in model.parameters():\n","#        print(param.requires_grad) \n","\n","#    print(model)\n","\n","    # Egogesture, with \"no-gesture\" training, weighted loss\n","    # class_weights = torch.cat((0.012*torch.ones([1, 83]), 0.00015*torch.ones([1, 1])), 1)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    # # nvgesture, with \"no-gesture\" training, weighted loss\n","    # class_weights = torch.cat((0.04*torch.ones([1, 25]), 0.0008*torch.ones([1, 1])), 1)\n","    # criterion = nn.CrossEntropyLoss(weight=class_weights, size_average=False)\n","\n","    # criterion = nn.CrossEntropyLoss()\n","    if not opt.no_cuda:\n","        model=model.cuda()\n","        criterion = criterion.cuda()\n","\n","    if opt.no_mean_norm and not opt.std_norm:\n","        norm_method = Normalize([0, 0, 0], [1, 1, 1])\n","    elif not opt.std_norm:\n","        norm_method = Normalize(opt.mean, [1, 1, 1])\n","    else:\n","        norm_method = Normalize(opt.mean, opt.std)\n","\n","    if not opt.no_train:\n","        assert opt.train_crop in ['random', 'corner', 'center']\n","        if opt.train_crop == 'random':\n","            crop_method = MultiScaleRandomCrop(opt.scales, opt.sample_size)\n","        elif opt.train_crop == 'corner':\n","            crop_method = MultiScaleCornerCrop(opt.scales, opt.sample_size)\n","        elif opt.train_crop == 'center':\n","            crop_method = MultiScaleCornerCrop(\n","                opt.scales, opt.sample_size, crop_positions=['c'])\n","        spatial_transform = Compose([\n","            #RandomHorizontalFlip(),\n","            RandomRotate(),\n","            #RandomResize(),\n","            #crop_method,\n","            ExtractRoi(),\n","            RandomResize(),           ####\n","            FinalSize(),              ####\n","            RandomBrightnessContrast(),  ####\n","            Random_Perspective(),       ####\n","            #MultiplyValues(),\n","            #Dropout(),\n","            #SaltImage(),\n","            #Gaussian_blur(),\n","            SpatialElasticDisplacement(),\n","            ToTensor(opt.norm_value), norm_method\n","        ])\n","        temporal_transform = TemporalRandomCrop(opt.sample_duration, opt.downsample)\n","        target_transform = ClassLabel()\n","        training_data = get_training_set(opt, spatial_transform,\n","                                         temporal_transform, target_transform)\n","        train_loader = torch.utils.data.DataLoader(\n","            training_data,\n","            batch_size=opt.batch_size,\n","            shuffle=True,\n","            num_workers=opt.n_threads,\n","            pin_memory=True)\n","        train_logger = Logger(\n","            os.path.join(opt.result_path, opt.store_name + '_train.log'),\n","            ['epoch', 'loss', 'prec1', 'lr'],opening_mode)   #####\n","        train_batch_logger = Logger(\n","            os.path.join(opt.result_path, 'train_batch.log'),\n","            ['epoch', 'batch', 'iter', 'loss', 'prec1', 'lr'],opening_mode)\n","\n","        if opt.nesterov:\n","            dampening = 0\n","        else:\n","            dampening = opt.dampening\n","        optimizer = optim.SGD(\n","            parameters,\n","            lr=opt.learning_rate,\n","            momentum=opt.momentum,\n","            dampening=dampening,\n","            weight_decay=opt.weight_decay,\n","            nesterov=opt.nesterov)\n","        scheduler = lr_scheduler.ReduceLROnPlateau(\n","            optimizer, 'min', patience=opt.lr_patience)\n","    if not opt.no_val:\n","        spatial_transform = Compose([\n","          #  Scale(opt.sample_size),    #####\n","            #CenterCrop(opt.sample_size),  ##### \n","            ExtractRoi(),\n","            FinalSize(),        \n","            ToTensor(opt.norm_value), norm_method\n","        ])\n","        #temporal_transform = LoopPadding(opt.sample_duration)\n","        temporal_transform = TemporalCenterCrop(opt.sample_duration, opt.downsample)\n","        target_transform = ClassLabel()\n","        validation_data = get_validation_set(\n","            opt, spatial_transform, temporal_transform, target_transform)\n","        val_loader = torch.utils.data.DataLoader(\n","            validation_data,\n","            batch_size=opt.val_batch_size,\n","            shuffle=False,\n","            num_workers=opt.n_threads,\n","            pin_memory=True)\n","        val_logger = Logger(\n","            os.path.join(opt.result_path, opt.store_name + '_val.log'), ['epoch', 'loss', 'prec1'],opening_mode)\n","\n","    if opt.test:\n","        spatial_transform = Compose([\n","          #  Scale(opt.sample_size),    #####\n","            #CenterCrop(opt.sample_size),  #####  \n","            ExtractRoi(),\n","            FinalSize(),           \n","            ToTensor(opt.norm_value), norm_method\n","        ])\n","        #temporal_transform = LoopPadding(opt.sample_duration)\n","        temporal_transform = TemporalCenterCrop(opt.sample_duration, opt.downsample)\n","        target_transform = ClassLabel()\n","        test_data = get_test_set(\n","            opt, spatial_transform, temporal_transform, target_transform)\n","        test_loader = torch.utils.data.DataLoader(\n","            test_data,\n","            batch_size=opt.test_batch_size,\n","            shuffle=False,\n","            num_workers=opt.n_threads,\n","            pin_memory=True)\n","        test_logger = Logger(\n","            os.path.join(opt.result_path, opt.store_name + '_test.log'), ['epoch', 'loss', 'prec1'],opening_mode)\n","\n","\n","    if opt.resume_path:\n","        print('loading checkpoint {}'.format(opt.resume_path))\n","        checkpoint = torch.load(opt.resume_path)\n","        assert opt.arch == checkpoint['arch']\n","        best_prec1 = checkpoint['best_prec1']\n","        opt.begin_epoch = checkpoint['epoch']\n","        model.load_state_dict(checkpoint['state_dict'])\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Total number of trainable parameters:  0\n","loading pretrained model /content/drive/My Drive/my_projects/ISLR/pretrained_models/jester_resnext_101_RGB_16_best.pth\n","[INFO]: EgoGesture Dataset - training, is loading...\n","dataset loading [0/619]\n","[INFO]: EgoGesture Dataset - validation, is loading...\n","dataset loading [0/107]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_IpBfGNmX-wb","executionInfo":{"status":"ok","timestamp":1609515374689,"user_tz":-330,"elapsed":1164,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}}},"source":["\n","if resume:\n","    checkpoint = torch.load(resume_path)\n","    assert opt.arch == checkpoint['arch']\n","    model.load_state_dict(checkpoint['state_dict'])\n","    opt.begin_epoch = checkpoint['epoch']+1\n","    train_best_prec1 = checkpoint['train_best_prec1']\n","    train_best_loss = checkpoint['train_best_loss']\n","    if not opt.no_val:\n","        best_prec1 = checkpoint['best_prec1']\n","        best_loss = checkpoint['best_loss']\n","    if opt.test:\n","        test_best_prec1 = checkpoint['test_best_prec1']\n","        test_best_loss = checkpoint['test_best_loss']\n","else:\n","    train_best_loss=10\n","    best_loss=10\n","    test_best_loss=10\n","    train_best_prec1=0\n","    best_prec1 = 0\n","    test_best_prec1=0\n","\n","train_loss=[]\n","val_loss=[]\n","test_loss=[]\n","train_acc=[]\n","val_acc=[]\n","test_acc=[]\n","\n","def fit(lr,epochs,model_checkpoint_path):\n","    global train_best_prec1,best_prec1,test_best_prec1,train_best_loss,best_loss,test_best_loss\n","    global train_loss,val_loss,test_loss,train_acc,val_acc,test_acc\n","\n","    opt.learning_rate=lr\n","    opt.n_epochs=epochs\n","    \n","    print('run')\n","    for i in range(opt.begin_epoch, opt.n_epochs + 1):\n","    # for i in range(opt.begin_epoch, opt.begin_epoch + 10):\n","        if not opt.no_train:\n","            adjust_learning_rate(optimizer, i, opt)\n"," #            print('lr first and last layer\\n',optimizer.param_groups[0]['lr'],optimizer.param_groups[313]['lr'])\n","            loss,acc=train_epoch(i, train_loader, model, criterion, optimizer, opt,\n","                        train_logger, train_batch_logger)\n","            \n","            train_loss.append(loss)\n","            train_acc.append(acc) \n","\n","            if acc > train_best_prec1:\n","               train_best_prec1=acc\n","               torch.save(model.state_dict(),'/content/drive/My Drive/my_projects/ISLR/my_model/n/with_none/wo_val_test/train_best_acc_model_state_dict.pth')\n","\n","            if loss<train_best_loss:\n","                train_best_loss=loss\n","                torch.save(model.state_dict(),'/content/drive/My Drive/my_projects/ISLR/my_model/n/with_none/wo_val_test/train_best_loss_model_state_dict.pth')\n","   \n","\n","            state = {\n","                'epoch': i,\n","                'arch': opt.arch,\n","                'state_dict': model.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'train_best_prec1': train_best_prec1,\n","                'train_best_loss': train_best_loss\n","                }\n","            if not opt.no_val:\n","              state.update({'best_prec1': best_prec1,\n","                            'best_loss': best_loss})\n","            if opt.test:\n","              state.update({'test_best_prec1': test_best_prec1,\n","                            'test_best_loss': test_best_loss})\n","           # save_checkpoint(state, False, opt)  ####\n","\n","            torch.save(state,model_checkpoint_path)\n","            \n","        if not opt.no_val:\n","            print('validation at epoch {}'.format(i))\n","            validation_loss, prec1 = val_epoch(i, val_loader, model, criterion, opt,\n","                                        val_logger)\n","            \n","            val_loss.append(validation_loss)    ####\n","            val_acc.append(prec1)\n","\n","            is_best = prec1 > best_prec1\n","            best_prec1 = max(prec1, best_prec1)\n","            if is_best:\n","               torch.save(model.state_dict(),'/content/drive/My Drive/my_projects/ISLR/my_model/n/with_none/merged_testset/best_acc_model_state_dict.pth')\n","\n","            if validation_loss<best_loss:\n","                best_loss=validation_loss\n","                torch.save(model.state_dict(),'/content/drive/My Drive/my_projects/ISLR/my_model/n/with_none/merged_testset/best_loss_model_state_dict.pth')\n","                \n","            state = {\n","                'epoch': i,\n","                'arch': opt.arch,\n","                'state_dict': model.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'best_prec1': best_prec1\n","                }\n","           # save_checkpoint(state, is_best, opt)         ####\n","\n","        if opt.test:\n","            print('testing at epoch {}'.format(i))\n","            testing_loss, test_prec1 = val_epoch(i, test_loader, model, criterion, opt,\n","                                        test_logger)\n","            \n","            test_loss.append(testing_loss)    ####\n","            test_acc.append(test_prec1)\n","\n","            test_is_best = test_prec1 > test_best_prec1\n","            test_best_prec1 = max(test_prec1, test_best_prec1)\n","            if test_is_best:\n","               torch.save(model.state_dict(),'/content/drive/My Drive/my_projects/ISLR/my_model/n/with_none/merged_testset/test_best_acc_model_state_dict.pth')\n","\n","            if testing_loss<test_best_loss:\n","                test_best_loss=testing_loss\n","                torch.save(model.state_dict(),'/content/drive/My Drive/my_projects/ISLR/my_model/n/with_none/merged_testset/test_best_loss_model_state_dict.pth')\n","                \n","            state = {\n","                'epoch': i,\n","                'arch': opt.arch,\n","                'state_dict': model.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'best_prec1': test_best_prec1\n","                }\n","\n","        \n","        print('train best prec:',train_best_prec1,'train best loss:',train_best_loss)\n","        if not opt.no_val:\n","            print('val best prec:',best_prec1,'val best loss:',best_loss)\n","        if opt.test:\n","            print('test best prec:',test_best_prec1,'test best loss:',test_best_loss)\n","        print('\\n')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsKyjW7payHi","executionInfo":{"status":"ok","timestamp":1609515377975,"user_tz":-330,"elapsed":1127,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}},"outputId":"4750be35-bcea-4fb8-ba07-f43aad8eb008"},"source":["print('train best prec:',train_best_prec1,'train best loss:',train_best_loss)#'\\nval best prec:',best_prec1,'val best loss:',best_loss,'\\ntest best prec:',test_best_prec1,'test best loss:',test_best_loss,'\\n')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["train best prec: 0 train best loss: 10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6qcrd_I1tQAa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609515384490,"user_tz":-330,"elapsed":1060,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}},"outputId":"1b9e0909-54ba-4b21-9be0-7ad00e8a22fa"},"source":["\r\n","opt.begin_epoch"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"9H4axU0CwH-6","executionInfo":{"status":"ok","timestamp":1609515399003,"user_tz":-330,"elapsed":1083,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}}},"source":["epochs=125\n","model_checkpoint_name='tmp.pth'#'checkpoint.pth'\n","model_checkpoint_path='/content/drive/My Drive/my_projects/ISLR/model_checkpoint/'+'with_none/merged_testset/'+model_checkpoint_name"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"lpZAPK5Bqqop"},"source":["## training last layer\n","for param in model.parameters():\n","      print(param.requires_grad)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0aUchPAYeuC"},"source":["lr=0.001\n","fit(lr,epochs,model_checkpoint_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qc_ZQHCHJ8Xc"},"source":["## fine tuning the model\n","for param in model.parameters():\n","      param.requires_grad=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v70K9EF3KtVW"},"source":["lr=0.0001\n","fit(lr,epochs,model_checkpoint_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WhclIyFQRdDT"},"source":["## plot top loss"]},{"cell_type":"code","metadata":{"id":"Oq6draeoJoET","executionInfo":{"status":"ok","timestamp":1609516751053,"user_tz":-330,"elapsed":1195,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}}},"source":["import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import torch\n","from torch.autograd import Variable\n","import numpy as np\n","import cv2\n","\n","def plot_top_losses(topk=2,model=model,data_loader=None):\n","    preds=torch.tensor([]).cuda()\n","    targs=torch.tensor([]).cuda()\n","\n","    model.eval()\n","    j=1\n","    for i,t in data_loader:\n","\n","      t=t.cuda()\n","     # with torch.no_grad():\n","     #     inputs=Variable(i) \n","     #     outputs=Variable(t)\n","      inputs=i\n","      outputs=t\n","      pred=model(inputs)\n","      preds=torch.cat((preds.data,pred),0)\n","      targs=torch.cat((targs,outputs),0)\n","\n","\n","    samp_loss=F.cross_entropy(preds,targs.long(),reduction='none')\n","    assert len(samp_loss)==len(data_loader.dataset.data)\n","    \n","    pred_cls=preds.argmax(dim=1)\n","\n","    print('accuracy:',sum(torch.eq(pred_cls,targs))*100/len(targs))\n","\n","    loss_indx=samp_loss.argsort(descending=True)\n","    path=[]\n","    segment=[]\n","    for k,i in enumerate(loss_indx[:topk]):\n","        i=int(i.cpu())\n","        path.append(data_loader.dataset.data[i]['video'])\n","        segment.append(data_loader.dataset.data[i]['segment'])\n","        print('\\n\\n',k,'\\npath:',path[-1],'\\nsegment',segment[-1],'\\nloss:',samp_loss[i].data,'\\nprediction',F.softmax(preds[i].data),'\\npred_cls:',pred_cls[i],',\\tact_cls:',targs[i])\n","        frm_arr=data_loader.dataset[i][0].permute(1,2,3,0)\n","        frm_arr=(frm_arr+torch.tensor(opt.mean)).int()\n","        rows,cols=2,8\n","        ln=16\n","        fig,ax=plt.subplots(rows,cols,figsize=(cols*2.25,rows*2.5))\n","        for i in range(ln):\n","            frame=cv2.cvtColor(np.uint8(frm_arr[i]),cv2.COLOR_BGR2RGB)\n","            ax[i//cols,i%cols].imshow(frame)\n","            ax[i//cols,i%cols].set_title(i)\n","        plt.show()"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Cjnz0Iodw4i","executionInfo":{"status":"ok","timestamp":1609516250513,"user_tz":-330,"elapsed":1073,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}},"outputId":"1314e6e3-012e-4dd4-f8c2-0752f0b755d2"},"source":["import gc\n","gc.collect()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2009"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vyMomBOrL-q","executionInfo":{"status":"ok","timestamp":1609516253143,"user_tz":-330,"elapsed":739,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}},"outputId":"1f6b8118-0e15-4a6f-c4f4-a9f9e4b50bbe"},"source":["#torch.cuda.empty_cache()\n","torch.cuda.memory_reserved()/10**9"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.201326592"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQf-ROuqpaP3","executionInfo":{"status":"ok","timestamp":1609516259212,"user_tz":-330,"elapsed":1462,"user":{"displayName":"Faiz Malik","photoUrl":"","userId":"15357754248939835417"}},"outputId":"b10110c2-8df1-47a6-bafa-e306c090e8d8"},"source":["#model=torch.load('/content/drive/MyDrive/my_projects/ISLR/my_model/classifier_whole_model.pth')\r\n","model.load_state_dict(torch.load('/content/drive/MyDrive/my_projects/ISLR/my_model/n/with_none/merged_testset/best_acc_model_state_dict.pth'))"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"G83VBvpiOlMT"},"source":["# with none_class and more_epoch model\r\n","plot_top_losses(20,model, val_loader)\r\n","torch.cuda.empty_cache()\r\n","torch.cuda.memory_reserved()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U6di2o3JMABL"},"source":["# with none_class and more_epoch model\r\n","plot_top_losses(80,model, test_loader)\r\n","torch.cuda.empty_cache()\r\n","torch.cuda.memory_reserved()"],"execution_count":null,"outputs":[]}]}